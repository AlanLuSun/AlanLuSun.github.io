---
title: "Viewpoint Estimation using Triplet Loss with A Novel Viewpoint-based Input Selection Strategy"
collection: publications
permalink: /publication/2019-04-01-Viewpoint-Estimation-using-Triplet-Loss/
excerpt: '> *>Chanjian Gu, **Changsheng Lu**, Chanchen Gu and Xinping Guan*<br>>Viewpoint estimation is a fundamental procedure in vision-based robot tasks. A good viewpoint of the camera relative to objects can help the visual system perform better both in observation and manipulation. Recently, CNN-based algorithms, which can effectively extract discriminative features from images in challenging conditions are utilized to handle the viewpoint estimation problem. However, most existing algorithms focus on how to leverage the extracted deep features while neglecting the spatial relationship among images that captured from various viewpoints. In this paper, we present a deep metric learning method for solving the viewpoint estimation problem. A triplet loss with a novel viewpoint-based input selection strategy is introduced, which could learn more powerful features after incorporating the spatial relationship between viewpoints. Combined with the traditional classification loss, the presented loss can further enhance the discriminative power of features. To evaluate the performance of our method, a dataset containing a large number of images generated from five different texture-less workpieces is built and the experiment results show the effectiveness of the proposed method.'
date: 2019-04-01
venue: '--'
#paperurl: 'https://ieeexplore.ieee.org/document/8296246/'
#citation: 'Changsheng Lu, Siyu Xia, Wanming Huang, Ming Shao, Yun Fu. Circle Detection by Arc-support Line Segments. In: The 24rd IEEE International Conference on Image Processing (ICIP).'
---

<!-- Journal: -->
<!-- === -->
<!-- Submitted to IEEE Transactions on Image Processing -->  

Authors: 
===
Chanjian Gu, **Changsheng Lu**, Chanchen Gu and Xinping Guan

Abstract: 
===
Viewpoint estimation is a fundamental procedure in vision-based robot tasks. A good viewpoint of the camera relative to objects can help the visual system perform better both in observation and manipulation. Recently, CNN-based algorithms, which can effectively extract discriminative features from images in challenging conditions are utilized to handle the viewpoint estimation problem. However, most existing algorithms focus on how to leverage the extracted deep features while neglecting the spatial relationship among images that captured from various viewpoints. In this paper, we present a deep metric learning method for solving the viewpoint estimation problem. A triplet loss with a novel viewpoint-based input selection strategy is introduced, which could learn more powerful features after incorporating the spatial relationship between viewpoints. Combined with the traditional classification loss, the presented loss can further enhance the discriminative power of features. To evaluate the performance of our method, a dataset containing a large number of images generated from five different texture-less workpieces is built and the experiment results show the effectiveness of the proposed method.  

More details:
===  
- click [Download paper](https://iopscience.iop.org/article/10.1088/1742-6596/1207/1/012009/meta) or [here](https://iopscience.iop.org/article/10.1088/1742-6596/1207/1/012009/pdf).  
<!-- - [Download paper](https://arxiv.org/abs/1810.03243v3).-->
